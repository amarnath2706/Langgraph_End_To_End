{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "The Sky, a canvas vast and deep,\n",
      "Where clouds like ships on oceans sleep,\n",
      "A boundless blue, a fiery red,\n",
      "A swirling grey above our head.\n",
      "By day, a dome of dazzling light,\n",
      "By night, a cloak of starry night.\n",
      "\n",
      "(Verse 2)\n",
      "The sun, a painter bold and bright,\n",
      "With strokes of gold and amber light,\n",
      "He paints the dawn, a rosy hue,\n",
      "And sets the west in shades of blue.\n",
      "The moon, a pearl of silver sheen,\n",
      "Hangs in the dark, a silent queen.\n",
      "\n",
      "(Verse 3)\n",
      "The wind, a sculptor, swift and strong,\n",
      "Shapes clouds to figures, righting wrong,\n",
      "From fluffy sheep to towering peaks,\n",
      "A fleeting beauty that he speaks.\n",
      "He whispers secrets to the trees,\n",
      "And rustles leaves upon the breeze.\n",
      "\n",
      "(Verse 4)\n",
      "The rain, a weeping, gentle hand,\n",
      "That cleanses earth, across the land,\n",
      "A silver curtain, soft and low,\n",
      "That washes all the dust below.\n",
      "Then rainbows arch, a vibrant sign,\n",
      "A promise whispered, so divine.\n",
      "\n",
      "(Verse 5)\n",
      "The stars, like diamonds scattered wide,\n",
      "Across the velvet, dark inside,\n",
      "They twinkle bright, a cosmic dance,\n",
      "A silent, watchful, mystic trance.\n",
      "They guide the lost, a beacon clear,\n",
      "And banish shadows, far and near.\n",
      "\n",
      "(Verse 6)\n",
      "Oh, Sky, your beauty knows no end,\n",
      "A timeless wonder, friend to friend,\n",
      "A boundless space, where dreams take flight,\n",
      "A tapestry of day and night.\n",
      "Forever watching, calm and grand,\n",
      "Above this weary, mortal land.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(\"Write a ballad about Sky\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#Create a retriever - RAG\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "\n",
    "#Chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Prompt---input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "### Generate - RAG Chain\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(f\"---Prompt---{prompt}\")\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, an agent is a system using a large language model (LLM) as its core controller.  It's complemented by key components like planning, memory (short-term and long-term), and tool use to solve complex problems autonomously.  Examples include AutoGPT, GPT-Engineer, and BabyAGI.\n"
     ]
    }
   ],
   "source": [
    "#Let's test the RAG Chain now\n",
    "question = \"What is an agent?\"\n",
    "generation = rag_chain.invoke({\"context\":docs,\"question\":question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader or document grader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "#testing the document\n",
    "question = \"agent memory\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "question = \"Charlie Chaplin\"\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the different types of agent memory and how do they work?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query rewritter\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create a required function\n",
    "#Retriever function\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.get_relevant_documents(question)\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question,}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grade document\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    \n",
    "    filtered_docs = []\n",
    "\n",
    "    web_search = \"No\"\n",
    "\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"documents\": d.page_content}\n",
    "        )\n",
    "        print(f\"this is score {score}\")\n",
    "\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE : DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE : DOCUMENT NOT RELEVANT---\")\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\":filtered_docs,\"question\":question,\"web_search\":web_search}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "    \n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"generation\": generation,\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform Query\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web search\n",
    "from langchain.schema import Document\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide to generate - condition check\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG is working fine. Now let's implement the corrective RAG\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a work flow\n",
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str] #Why we use all this inside the state? because i want to float all values through out the nodes, so we can define anything and its not the thumbrule to define.\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2ec86d684c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_node\", web_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2ec86d684c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Edges\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the workflow\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question', 'documents']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(inputs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# Node\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         pprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1670\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1667\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1671\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1672\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1673\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1674\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1675\u001b[0m         ):\n\u001b[0;32m   1676\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langgraph\\pregel\\runner.py:171\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    169\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langgraph\\utils\\runnable.py:448\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    445\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 448\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langgraph\\utils\\runnable.py:219\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 219\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m, in \u001b[0;36mgrade_documents\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     19\u001b[0m web_search \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m---> 22\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_grader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is score \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m     grade \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39mbinary_score\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langchain_core\\runnables\\base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langchain_core\\prompts\\base.py:208\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    207\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langchain_core\\runnables\\base.py:1925\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1921\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1922\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1923\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1924\u001b[0m         Output,\n\u001b[1;32m-> 1925\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1926\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m             config,\n\u001b[0;32m   1930\u001b[0m             run_manager,\n\u001b[0;32m   1931\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1932\u001b[0m         ),\n\u001b[0;32m   1933\u001b[0m     )\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1935\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langchain_core\\prompts\\base.py:182\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32mc:\\Users\\Toshiba\\anaconda3\\envs\\langgraphe2e\\lib\\site-packages\\langchain_core\\prompts\\base.py:176\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    170\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    171\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m     )\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    177\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'document'}.  Expected: ['document', 'question'] Received: ['question', 'documents']\\nNote: if you intended {document} to be part of the string and not a variable, please escape it with double curly braces like: '{{document}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraphe2e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
